{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework #4\n",
    "\n",
    "\n",
    "The howework is due May 23rd 11:59PM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Bike sharing dataset\n",
    "\n",
    "This is a dataset of bike sharing data from 2011 and 2012 from Washington D.C. and is \n",
    "publicly available in [here](http://capitalbikeshare.com/system-data). Read the [README](./data/bike_sharing/Readme.txt) for details.\n",
    "\n",
    "For this question, construct  \n",
    "\n",
    "* a decision tree model\n",
    "* a random forest\n",
    "* a XGBoost tree model\n",
    "\n",
    "to predict\n",
    "\n",
    "1. the weather situation ('weathersit' column) using other columns.\n",
    "2. the number of bikes ('cnt' column) using other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>331</td>\n",
       "      <td>654</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>131</td>\n",
       "      <td>670</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>120</td>\n",
       "      <td>1229</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>108</td>\n",
       "      <td>1454</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>82</td>\n",
       "      <td>1518</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>727</td>\n",
       "      <td>2012-12-27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.254167</td>\n",
       "      <td>0.226642</td>\n",
       "      <td>0.652917</td>\n",
       "      <td>0.350133</td>\n",
       "      <td>247</td>\n",
       "      <td>1867</td>\n",
       "      <td>2114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>728</td>\n",
       "      <td>2012-12-28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.255046</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.155471</td>\n",
       "      <td>644</td>\n",
       "      <td>2451</td>\n",
       "      <td>3095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>729</td>\n",
       "      <td>2012-12-29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.242400</td>\n",
       "      <td>0.752917</td>\n",
       "      <td>0.124383</td>\n",
       "      <td>159</td>\n",
       "      <td>1182</td>\n",
       "      <td>1341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>730</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255833</td>\n",
       "      <td>0.231700</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.350754</td>\n",
       "      <td>364</td>\n",
       "      <td>1432</td>\n",
       "      <td>1796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>731</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.215833</td>\n",
       "      <td>0.223487</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>0.154846</td>\n",
       "      <td>439</td>\n",
       "      <td>2290</td>\n",
       "      <td>2729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>731 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     instant      dteday  season  yr  mnth  holiday  weekday  workingday  \\\n",
       "0          1  2011-01-01       1   0     1        0        6           0   \n",
       "1          2  2011-01-02       1   0     1        0        0           0   \n",
       "2          3  2011-01-03       1   0     1        0        1           1   \n",
       "3          4  2011-01-04       1   0     1        0        2           1   \n",
       "4          5  2011-01-05       1   0     1        0        3           1   \n",
       "..       ...         ...     ...  ..   ...      ...      ...         ...   \n",
       "726      727  2012-12-27       1   1    12        0        4           1   \n",
       "727      728  2012-12-28       1   1    12        0        5           1   \n",
       "728      729  2012-12-29       1   1    12        0        6           0   \n",
       "729      730  2012-12-30       1   1    12        0        0           0   \n",
       "730      731  2012-12-31       1   1    12        0        1           1   \n",
       "\n",
       "     weathersit      temp     atemp       hum  windspeed  casual  registered  \\\n",
       "0             2  0.344167  0.363625  0.805833   0.160446     331         654   \n",
       "1             2  0.363478  0.353739  0.696087   0.248539     131         670   \n",
       "2             1  0.196364  0.189405  0.437273   0.248309     120        1229   \n",
       "3             1  0.200000  0.212122  0.590435   0.160296     108        1454   \n",
       "4             1  0.226957  0.229270  0.436957   0.186900      82        1518   \n",
       "..          ...       ...       ...       ...        ...     ...         ...   \n",
       "726           2  0.254167  0.226642  0.652917   0.350133     247        1867   \n",
       "727           2  0.253333  0.255046  0.590000   0.155471     644        2451   \n",
       "728           2  0.253333  0.242400  0.752917   0.124383     159        1182   \n",
       "729           1  0.255833  0.231700  0.483333   0.350754     364        1432   \n",
       "730           2  0.215833  0.223487  0.577500   0.154846     439        2290   \n",
       "\n",
       "      cnt  \n",
       "0     985  \n",
       "1     801  \n",
       "2    1349  \n",
       "3    1562  \n",
       "4    1600  \n",
       "..    ...  \n",
       "726  2114  \n",
       "727  3095  \n",
       "728  1341  \n",
       "729  1796  \n",
       "730  2729  \n",
       "\n",
       "[731 rows x 16 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike = pd.read_csv('data/bike_sharing/day.csv')\n",
    "bike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cnt=bike.iloc[:,2:-1]\n",
    "x_weather = bike.drop(['instant', 'dteday',\"weathersit\"], axis=1)\n",
    "\n",
    "y_cnt=bike[\"cnt\"]\n",
    "y_weather=bike[\"weathersit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       985\n",
       "1       801\n",
       "2      1349\n",
       "3      1562\n",
       "4      1600\n",
       "       ... \n",
       "726    2114\n",
       "727    3095\n",
       "728    1341\n",
       "729    1796\n",
       "730    2729\n",
       "Name: cnt, Length: 731, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While weatherit has only [1,2,3] responses, It can be determined by decisiontree classifier. But \"cnt\" needs decision tree regressor.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6938775510204082"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(x_weather,y_weather,test_size=0.2)\n",
    "classifier = DecisionTreeClassifier(criterion='entropy')\n",
    "classifier.fit(X_train,y_train)\n",
    "classifier.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9871495470120712"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regressor = DecisionTreeRegressor()\n",
    "X_train,X_test,y_train,y_test=train_test_split(x_cnt,y_cnt,test_size=0.2)\n",
    "regressor.fit(X_train,y_train)\n",
    "regressor.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8095238095238095"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "X_train,X_test,y_train,y_test=train_test_split(x_weather,y_weather,test_size=0.2)\n",
    "classifier = RandomForestClassifier(criterion='entropy')\n",
    "classifier.fit(X_train,y_train)\n",
    "classifier.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9965371830597908"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = RandomForestRegressor()\n",
    "X_train,X_test,y_train,y_test=train_test_split(x_cnt,y_cnt,test_size=0.2)\n",
    "regressor.fit(X_train,y_train)\n",
    "regressor.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.4.2-py3-none-win_amd64.whl (97.8 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\pc\\anaconda3\\envs\\env\\lib\\site-packages (from xgboost) (1.18.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\pc\\anaconda3\\envs\\env\\lib\\site-packages (from xgboost) (1.6.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7687074829931972"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "classifier=xgb.XGBClassifier(eval_metric= 'mlogloss')\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(x_weather,y_weather,test_size=0.2)\n",
    "\n",
    "classifier.fit(X_train,y_train)\n",
    "classifier.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9938840661536381"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = xgb.XGBRegressor()\n",
    "X_train,X_test,y_train,y_test=train_test_split(x_cnt,y_cnt,test_size=0.2)\n",
    "regressor.fit(X_train,y_train)\n",
    "regressor.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Education datataset\n",
    "\n",
    "This dataset is taken from [Kaggle](https://www.kaggle.com/spscientist/students-performance-in-exams). For this dataset, construct a decision tree regression and a XGBoost regression model to predict\n",
    "\n",
    "1. math score\n",
    "2. reading score\n",
    "3. writing score\n",
    "\n",
    "Beware: you might have to transform the data first before you train and test your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>group A</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>female</td>\n",
       "      <td>group E</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>88</td>\n",
       "      <td>99</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>male</td>\n",
       "      <td>group C</td>\n",
       "      <td>high school</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>62</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>high school</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>completed</td>\n",
       "      <td>59</td>\n",
       "      <td>71</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>female</td>\n",
       "      <td>group D</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>68</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>female</td>\n",
       "      <td>group D</td>\n",
       "      <td>some college</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>77</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender race/ethnicity parental level of education         lunch  \\\n",
       "0    female        group B           bachelor's degree      standard   \n",
       "1    female        group C                some college      standard   \n",
       "2    female        group B             master's degree      standard   \n",
       "3      male        group A          associate's degree  free/reduced   \n",
       "4      male        group C                some college      standard   \n",
       "..      ...            ...                         ...           ...   \n",
       "995  female        group E             master's degree      standard   \n",
       "996    male        group C                 high school  free/reduced   \n",
       "997  female        group C                 high school  free/reduced   \n",
       "998  female        group D                some college      standard   \n",
       "999  female        group D                some college  free/reduced   \n",
       "\n",
       "    test preparation course  math score  reading score  writing score  \n",
       "0                      none          72             72             74  \n",
       "1                 completed          69             90             88  \n",
       "2                      none          90             95             93  \n",
       "3                      none          47             57             44  \n",
       "4                      none          76             78             75  \n",
       "..                      ...         ...            ...            ...  \n",
       "995               completed          88             99             95  \n",
       "996                    none          62             55             55  \n",
       "997               completed          59             71             65  \n",
       "998               completed          68             78             77  \n",
       "999                    none          77             86             86  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "education = pd.read_csv('./data/student_performance/StudentsPerformance.csv')\n",
    "education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ys_dict={\"y_math\":education[\"math score\"],\"y_reading\":education[\"reading score\"],\"y_writing\":education[\"writing score\"]}\n",
    "Xs_dict={\"X_math\":education.drop([\"math score\"],axis=1),\"X_reading\":education.drop([\"reading score\"],axis=1),\n",
    "         \"X_writing\":education.drop([\"writing score\"],axis=1)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've created 3 X and y dict in order to apply models in a loop. And o function is prepared for different models and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_exp(model,X,y):\n",
    "    ohe=OneHotEncoder()\n",
    "    X=ohe.fit_transform(X).toarray()\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "    if model==\"xgb\":\n",
    "        regressor = xgb.XGBRegressor()\n",
    "        regressor.fit(X_train,y_train)\n",
    "        sc=regressor.score(X_test,y_test)\n",
    "    if model==\"Dtr\":\n",
    "        regressor = RandomForestRegressor()\n",
    "        regressor.fit(X_train,y_train)\n",
    "        sc=regressor.score(X_test,y_test)\n",
    "    return sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " y_math score of model xgb is 0.7349402984570185\n",
      " y_reading score of model xgb is 0.7025908525291167\n",
      " y_writing score of model xgb is 0.7152409227785377\n",
      " y_math score of model Dtr is 0.5634743406960401\n",
      " y_reading score of model Dtr is 0.603221153531865\n",
      " y_writing score of model Dtr is 0.6060841328203272\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "y_s=[\"y_math\",\"y_reading\",\"y_writing\"]\n",
    "X_s=[\"X_math\",\"X_reading\",\"X_writing\"]\n",
    "models=[\"xgb\",\"Dtr\"]\n",
    "\n",
    "for i in range(len(models)):\n",
    "    for j in range(len(y_s)):\n",
    "        print(\" {} score of model {} is {}\".format(y_s[j],models[i],do_exp(models[i],Xs_dict[X_s[j]],ys_dict[y_s[j]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>checkin</th>\n",
       "      <th>checkout</th>\n",
       "      <th>city_id</th>\n",
       "      <th>device_class</th>\n",
       "      <th>affiliate_id</th>\n",
       "      <th>booker_country</th>\n",
       "      <th>hotel_country</th>\n",
       "      <th>utrip_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000027</td>\n",
       "      <td>2016-08-13</td>\n",
       "      <td>2016-08-14</td>\n",
       "      <td>8183</td>\n",
       "      <td>desktop</td>\n",
       "      <td>7168</td>\n",
       "      <td>Elbonia</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>1000027_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000027</td>\n",
       "      <td>2016-08-14</td>\n",
       "      <td>2016-08-16</td>\n",
       "      <td>15626</td>\n",
       "      <td>desktop</td>\n",
       "      <td>7168</td>\n",
       "      <td>Elbonia</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>1000027_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000027</td>\n",
       "      <td>2016-08-16</td>\n",
       "      <td>2016-08-18</td>\n",
       "      <td>60902</td>\n",
       "      <td>desktop</td>\n",
       "      <td>7168</td>\n",
       "      <td>Elbonia</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>1000027_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000027</td>\n",
       "      <td>2016-08-18</td>\n",
       "      <td>2016-08-21</td>\n",
       "      <td>30628</td>\n",
       "      <td>desktop</td>\n",
       "      <td>253</td>\n",
       "      <td>Elbonia</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>1000027_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000033</td>\n",
       "      <td>2016-04-09</td>\n",
       "      <td>2016-04-11</td>\n",
       "      <td>38677</td>\n",
       "      <td>mobile</td>\n",
       "      <td>359</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Cobra Island</td>\n",
       "      <td>1000033_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166830</th>\n",
       "      <td>999855</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>2016-05-02</td>\n",
       "      <td>20345</td>\n",
       "      <td>mobile</td>\n",
       "      <td>359</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Fook Island</td>\n",
       "      <td>999855_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166831</th>\n",
       "      <td>999944</td>\n",
       "      <td>2016-06-23</td>\n",
       "      <td>2016-06-24</td>\n",
       "      <td>17944</td>\n",
       "      <td>desktop</td>\n",
       "      <td>4541</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Glubbdubdrib</td>\n",
       "      <td>999944_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166832</th>\n",
       "      <td>999944</td>\n",
       "      <td>2016-06-24</td>\n",
       "      <td>2016-06-27</td>\n",
       "      <td>47075</td>\n",
       "      <td>desktop</td>\n",
       "      <td>2322</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Glubbdubdrib</td>\n",
       "      <td>999944_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166833</th>\n",
       "      <td>999944</td>\n",
       "      <td>2016-06-27</td>\n",
       "      <td>2016-06-29</td>\n",
       "      <td>228</td>\n",
       "      <td>desktop</td>\n",
       "      <td>384</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Glubbdubdrib</td>\n",
       "      <td>999944_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166834</th>\n",
       "      <td>999944</td>\n",
       "      <td>2016-06-29</td>\n",
       "      <td>2016-06-30</td>\n",
       "      <td>62930</td>\n",
       "      <td>desktop</td>\n",
       "      <td>4541</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Glubbdubdrib</td>\n",
       "      <td>999944_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1166835 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id     checkin    checkout  city_id device_class  affiliate_id  \\\n",
       "0        1000027  2016-08-13  2016-08-14     8183      desktop          7168   \n",
       "1        1000027  2016-08-14  2016-08-16    15626      desktop          7168   \n",
       "2        1000027  2016-08-16  2016-08-18    60902      desktop          7168   \n",
       "3        1000027  2016-08-18  2016-08-21    30628      desktop           253   \n",
       "4        1000033  2016-04-09  2016-04-11    38677       mobile           359   \n",
       "...          ...         ...         ...      ...          ...           ...   \n",
       "1166830   999855  2016-05-01  2016-05-02    20345       mobile           359   \n",
       "1166831   999944  2016-06-23  2016-06-24    17944      desktop          4541   \n",
       "1166832   999944  2016-06-24  2016-06-27    47075      desktop          2322   \n",
       "1166833   999944  2016-06-27  2016-06-29      228      desktop           384   \n",
       "1166834   999944  2016-06-29  2016-06-30    62930      desktop          4541   \n",
       "\n",
       "        booker_country hotel_country   utrip_id  \n",
       "0              Elbonia        Gondal  1000027_1  \n",
       "1              Elbonia        Gondal  1000027_1  \n",
       "2              Elbonia        Gondal  1000027_1  \n",
       "3              Elbonia        Gondal  1000027_1  \n",
       "4               Gondal  Cobra Island  1000033_1  \n",
       "...                ...           ...        ...  \n",
       "1166830         Gondal   Fook Island   999855_1  \n",
       "1166831         Gondal  Glubbdubdrib   999944_1  \n",
       "1166832         Gondal  Glubbdubdrib   999944_1  \n",
       "1166833         Gondal  Glubbdubdrib   999944_1  \n",
       "1166834         Gondal  Glubbdubdrib   999944_1  \n",
       "\n",
       "[1166835 rows x 9 columns]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "booking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. booking.com Challenge\n",
    "\n",
    "This dataset is taken from [Booking.com Challenge ACM WSDM 2021](https://www.bookingchallenge.com/).\n",
    "\n",
    "The original challenge was to predict the final destination city of the trip by looking at the data at hand for each user. For this question, you are free to do whatever you like. Do something interesting with the data :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "booking = pd.read_csv('./data/booking/train_set.csv')\n",
    "\n",
    "booking[\"checkin\"]=pd.to_datetime(booking[\"checkin\"])\n",
    "booking[\"checkout\"]=pd.to_datetime(booking[\"checkout\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>checkin</th>\n",
       "      <th>checkout</th>\n",
       "      <th>city_id</th>\n",
       "      <th>device_class</th>\n",
       "      <th>affiliate_id</th>\n",
       "      <th>booker_country</th>\n",
       "      <th>hotel_country</th>\n",
       "      <th>utrip_id</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000027</td>\n",
       "      <td>2016-08-13</td>\n",
       "      <td>2016-08-14</td>\n",
       "      <td>8183</td>\n",
       "      <td>desktop</td>\n",
       "      <td>7168</td>\n",
       "      <td>Elbonia</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>1000027_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000027</td>\n",
       "      <td>2016-08-14</td>\n",
       "      <td>2016-08-16</td>\n",
       "      <td>15626</td>\n",
       "      <td>desktop</td>\n",
       "      <td>7168</td>\n",
       "      <td>Elbonia</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>1000027_1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000027</td>\n",
       "      <td>2016-08-16</td>\n",
       "      <td>2016-08-18</td>\n",
       "      <td>60902</td>\n",
       "      <td>desktop</td>\n",
       "      <td>7168</td>\n",
       "      <td>Elbonia</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>1000027_1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000027</td>\n",
       "      <td>2016-08-18</td>\n",
       "      <td>2016-08-21</td>\n",
       "      <td>30628</td>\n",
       "      <td>desktop</td>\n",
       "      <td>253</td>\n",
       "      <td>Elbonia</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>1000027_1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000033</td>\n",
       "      <td>2016-04-09</td>\n",
       "      <td>2016-04-11</td>\n",
       "      <td>38677</td>\n",
       "      <td>mobile</td>\n",
       "      <td>359</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Cobra Island</td>\n",
       "      <td>1000033_1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166830</th>\n",
       "      <td>999855</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>2016-05-02</td>\n",
       "      <td>20345</td>\n",
       "      <td>mobile</td>\n",
       "      <td>359</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Fook Island</td>\n",
       "      <td>999855_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166831</th>\n",
       "      <td>999944</td>\n",
       "      <td>2016-06-23</td>\n",
       "      <td>2016-06-24</td>\n",
       "      <td>17944</td>\n",
       "      <td>desktop</td>\n",
       "      <td>4541</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Glubbdubdrib</td>\n",
       "      <td>999944_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166832</th>\n",
       "      <td>999944</td>\n",
       "      <td>2016-06-24</td>\n",
       "      <td>2016-06-27</td>\n",
       "      <td>47075</td>\n",
       "      <td>desktop</td>\n",
       "      <td>2322</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Glubbdubdrib</td>\n",
       "      <td>999944_1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166833</th>\n",
       "      <td>999944</td>\n",
       "      <td>2016-06-27</td>\n",
       "      <td>2016-06-29</td>\n",
       "      <td>228</td>\n",
       "      <td>desktop</td>\n",
       "      <td>384</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Glubbdubdrib</td>\n",
       "      <td>999944_1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166834</th>\n",
       "      <td>999944</td>\n",
       "      <td>2016-06-29</td>\n",
       "      <td>2016-06-30</td>\n",
       "      <td>62930</td>\n",
       "      <td>desktop</td>\n",
       "      <td>4541</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Glubbdubdrib</td>\n",
       "      <td>999944_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1166835 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id    checkin   checkout  city_id device_class  affiliate_id  \\\n",
       "0        1000027 2016-08-13 2016-08-14     8183      desktop          7168   \n",
       "1        1000027 2016-08-14 2016-08-16    15626      desktop          7168   \n",
       "2        1000027 2016-08-16 2016-08-18    60902      desktop          7168   \n",
       "3        1000027 2016-08-18 2016-08-21    30628      desktop           253   \n",
       "4        1000033 2016-04-09 2016-04-11    38677       mobile           359   \n",
       "...          ...        ...        ...      ...          ...           ...   \n",
       "1166830   999855 2016-05-01 2016-05-02    20345       mobile           359   \n",
       "1166831   999944 2016-06-23 2016-06-24    17944      desktop          4541   \n",
       "1166832   999944 2016-06-24 2016-06-27    47075      desktop          2322   \n",
       "1166833   999944 2016-06-27 2016-06-29      228      desktop           384   \n",
       "1166834   999944 2016-06-29 2016-06-30    62930      desktop          4541   \n",
       "\n",
       "        booker_country hotel_country   utrip_id  delta  \n",
       "0              Elbonia        Gondal  1000027_1      1  \n",
       "1              Elbonia        Gondal  1000027_1      2  \n",
       "2              Elbonia        Gondal  1000027_1      2  \n",
       "3              Elbonia        Gondal  1000027_1      3  \n",
       "4               Gondal  Cobra Island  1000033_1      2  \n",
       "...                ...           ...        ...    ...  \n",
       "1166830         Gondal   Fook Island   999855_1      1  \n",
       "1166831         Gondal  Glubbdubdrib   999944_1      1  \n",
       "1166832         Gondal  Glubbdubdrib   999944_1      3  \n",
       "1166833         Gondal  Glubbdubdrib   999944_1      2  \n",
       "1166834         Gondal  Glubbdubdrib   999944_1      1  \n",
       "\n",
       "[1166835 rows x 10 columns]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "booking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, the checkin and checkout time has transformed to date. Then the staying duration is obtained, then   booker country and hotel country has been added to a array in order to tranform them with label encoder. Label encoder is fit to this array, then these two columns are transformed. Device class is also label encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "booking[\"delta\"]=(booking[\"checkout\"]-booking[\"checkin\"]).dt.days.astype(\"int16\")\n",
    "X=booking.drop([\"hotel_country\",\"checkin\",\"checkout\",\"utrip_id\"],axis=1)\n",
    "y=booking[\"hotel_country\"]\n",
    "\n",
    "le=LabelEncoder()\n",
    "le1=LabelEncoder()\n",
    "X_array=np.array(X[\"booker_country\"])\n",
    "y_array=np.array(y)\n",
    "fit_array=np.concatenate([X_array,y_array],axis=0)\n",
    "fit_array\n",
    "le.fit(fit_array)\n",
    "y_labeled=le.transform(y)\n",
    "X[\"booker_country\"]=le.transform(X[\"booker_country\"])\n",
    "X[\"device_class\"]=le1.fit_transform(X[\"device_class\"])\n",
    "X=X[0:100000]\n",
    "y_labeled=y_labeled[0:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\anaconda3\\envs\\env\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.764"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y_labeled,test_size=0.2)\n",
    "classifier=xgb.XGBClassifier(eval_metric= 'mlogloss')\n",
    "classifier.fit(X_train,y_train)\n",
    "classifier.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.432"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y_labeled,test_size=0.2)\n",
    "classifier=RandomForestClassifier()\n",
    "classifier.fit(X_train,y_train)\n",
    "classifier.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
