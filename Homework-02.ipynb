{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework #2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question #1\n",
    "\n",
    "There are four text files in the data folder\n",
    "\n",
    "* Atatürk's \"Nutuk\" in Turkish\n",
    "* Dicken's novel \"Great Expectations\" in English\n",
    "* Flauberts' novel \"Madam Bovary\" in French\n",
    "* A text file `unknown.txt` in an unknown language\n",
    "\n",
    "Your tasks are\n",
    "\n",
    "* Calculate how many times each character (letter) appear in each text.\n",
    "* Calculate the character distributions, i.e. using the character counts, calculate the probability of each character appearing in the text.\n",
    "* Find the set of characters common to all three texts.\n",
    "* Using the common set and the KL-divergence, show that each language have different character distributions.\n",
    "* Determine the language of the text file `unknown.txt` KL-divergence measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "letter amount of nutuk\n",
      "{'y': 29496, 'u': 39565, 'r': 74152, 'd': 45861, 'm': 70652, 'z': 15593, 'n': 78256, 'p': 7371, 'a': 118982, 'ç': 8613, 'l': 75010, 'ı': 44210, 'i': 100889, 'ş': 19525, 'g': 14552, 'e': 113678, 'ğ': 10530, 'ü': 19746, 'b': 29389, 'k': 48264, 't': 42730, 'h': 12834, 'ö': 7358, 'o': 20290, 's': 30794, '̇': 6346, 'â': 2643, 'v': 15618, 'c': 10929, 'î': 1469, 'f': 7489, '1': 14901, '5': 274, '2': 1432, '0': 13567, '9': 1132, '7': 184, '3': 478, '6': 177, 'j': 163, 'á': 2, '8': 209, 'ì': 5, 'û': 836, '4': 251, 'ó': 1, '\\x1b': 25980, 'w': 66, 'í': 4, 'ú': 1, '·': 6, '\\x7f': 22, 'q': 1, 'é': 30, 'x': 3, 'ß': 1, '«': 6, '»': 6}\n",
      "letter amount of dickens\n",
      "{'\\ufeff': 1, 't': 70355, 'h': 48738, 'e': 93720, 'p': 13417, 'r': 42122, 'o': 61277, 'j': 1759, 'c': 17625, 'g': 16871, 'u': 22257, 'n': 53781, 'b': 12451, 'k': 7680, 'f': 16130, 'a': 64021, 'x': 1126, 'i': 55801, 's': 45936, 'y': 16410, 'l': 28564, 'd': 37182, 'w': 20526, 'm': 22906, 'v': 6896, '1': 64, '9': 11, '8': 12, '4': 14, '0': 30, '2': 13, '7': 10, '6': 8, '’': 2596, '—': 1151, 'q': 710, '“': 3945, '”': 3908, 'z': 166, '‘': 95, 'ô': 1, 'ê': 1, '3': 11, '5': 12}\n",
      "letter amount of bovary\n",
      "{'\\ufeff': 1, 't': 40678, 'h': 6177, 'e': 79764, 'p': 14651, 'r': 35857, 'o': 29092, 'j': 2052, 'c': 16344, 'g': 5190, 'u': 33588, 'n': 36296, 'b': 6245, 'k': 154, 'f': 5880, 'm': 15786, 'a': 46611, 'd': 20056, 'v': 8791, 'y': 2029, 's': 44074, 'l': 35195, 'i': 40356, 'w': 280, '2': 21, '6': 14, '0': 21, '4': 20, '1': 87, '5': 28, '8': 18, '7': 11, 'è': 1651, 'x': 2116, 'à': 2810, 'é': 8295, 'z': 678, 'ê': 1196, 'q': 5709, 'ç': 477, 'î': 328, 'ù': 293, 'â': 410, 'û': 241, 'ï': 37, 'ô': 296, '«': 120, '»': 112, 'ë': 9, '9': 17, '3': 20, 'ü': 5, '°': 4}\n",
      "letter amount of unknown\n",
      "{'f': 27, 'o': 92, 'u': 21, 'r': 79, 's': 43, 'c': 31, 'e': 165, 'a': 102, 'n': 77, 'd': 58, 'v': 24, 'y': 10, 'g': 28, 't': 126, 'h': 80, 'b': 14, 'i': 68, 'w': 28, 'l': 42, 'p': 15, 'm': 13, 'q': 1, 'k': 3}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "nutuk=open('ataturk_nutuk.txt','r+',encoding='utf-8')\n",
    "dickens=open(\"dickens_great_expectations.txt\",\"r+\",encoding=\"utf-8\")\n",
    "bovary= open(\"flaubert_madame_bovary.txt\",\"r+\",encoding='utf-8') \n",
    "unknown=open(\"unknown.txt\",\"r+\",encoding='utf-8')\n",
    "\n",
    "counter1=dict()\n",
    "counter2=dict()\n",
    "counter3=dict()\n",
    "counter4=dict()\n",
    "\n",
    "text1=nutuk.read()\n",
    "text2=dickens.read()\n",
    "text3=bovary.read()\n",
    "text4=unknown.read()\n",
    "\n",
    "words1=text1.split()\n",
    "words2=text2.split()\n",
    "words3=text3.split()\n",
    "words4=text4.split()\n",
    "\n",
    "for i in range(len(words1)):    \n",
    "    words1[i]=words1[i].lower()\n",
    "    words1[i] = words1[i].translate(words1[i].maketrans(\"\", \"\", string.punctuation)) \n",
    "for i in range(len(words2)):    \n",
    "    words2[i]=words2[i].lower()\n",
    "    words2[i] = words2[i].translate(words2[i].maketrans(\"\", \"\", string.punctuation)) \n",
    "for i in range(len(words3)):    \n",
    "    words3[i]=words3[i].lower()\n",
    "    words3[i] = words3[i].translate(words3[i].maketrans(\"\", \"\", string.punctuation)) \n",
    "for i in range(len(words4)):    \n",
    "    words4[i]=words4[i].lower()\n",
    "    words4[i] = words4[i].translate(words4[i].maketrans(\"\", \"\", string.punctuation)) \n",
    "print(\"letter amount of nutuk\")\n",
    "\n",
    "for word in words1:\n",
    "    for char in word:\n",
    "        if char in counter1:\n",
    "            counter1[char]+=1\n",
    "        else:\n",
    "            counter1[char]=1\n",
    "print(counter1)\n",
    "print(\"letter amount of dickens\")\n",
    "for word in words2:\n",
    "    for char in word:\n",
    "        if char in counter2:\n",
    "            counter2[char]+=1\n",
    "        else:\n",
    "            counter2[char]=1\n",
    "print(counter2)\n",
    "print(\"letter amount of bovary\")\n",
    "for word in words3:\n",
    "    for char in word:\n",
    "        if char in counter3:\n",
    "            counter3[char]+=1\n",
    "        else:\n",
    "            counter3[char]=1\n",
    "print(counter3)\n",
    "print(\"letter amount of unknown\")\n",
    "for word in words4:\n",
    "    for char in word:\n",
    "        if char in counter4:\n",
    "            counter4[char]+=1\n",
    "        else:\n",
    "            counter4[char]=1\n",
    "print(counter4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc1=list(counter1.values())\n",
    "lc2=list(counter2.values())\n",
    "lc3=list(counter3.values())\n",
    "lc4=list(counter4.values())\n",
    "\n",
    "lc1_k=list(counter1.keys())\n",
    "lc2_k=list(counter2.keys())\n",
    "lc3_k=list(counter3.keys())\n",
    "lc4_k=list(counter4.keys())\n",
    "\n",
    "total_letter_c1=np.sum(lc1)\n",
    "total_letter_c2=np.sum(lc2)\n",
    "total_letter_c3=np.sum(lc3)\n",
    "total_letter_c4=np.sum(lc4)\n",
    "\n",
    "probsc1=lc1/total_letter_c1\n",
    "probsc2=lc2/total_letter_c2\n",
    "probsc3=lc3/total_letter_c3\n",
    "probsc4=lc4/total_letter_c4\n",
    "\n",
    "zip1=zip(lc1_k,probsc1)\n",
    "zip2=zip(lc2_k,probsc2)\n",
    "zip3=zip(lc3_k,probsc3)\n",
    "zip4=zip(lc4_k,probsc4)\n",
    "\n",
    "dict1=dict(zip1)\n",
    "dict2=dict(zip2)\n",
    "dict3=dict(zip3)\n",
    "dict4=dict(zip4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'y'}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common=set( dict1.keys() ) & set( dict2.keys() ) & set(dict3.keys()) & set(dict4.keys())  \n",
    "common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "\n",
    "commondict1=dict()\n",
    "commondict2=dict()\n",
    "commondict3=dict()\n",
    "commondict4=dict()\n",
    "for letter in common:\n",
    "    commondict1[letter]=dict1[letter]\n",
    "    commondict2[letter]=dict2[letter]\n",
    "    commondict3[letter]=dict3[letter]\n",
    "    commondict4[letter]=dict4[letter]\n",
    "    \n",
    "valuecommon1=list(commondict1.values())\n",
    "valuecommon2=list(commondict2.values())\n",
    "valuecommon3=list(commondict3.values())\n",
    "valuecommon4=list(commondict4.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy between 4 and 1 is 0.43005894096312886\n",
      "entropy between 4 and 2 is 0.038013041187527796\n",
      "entropy between 4 and 3 is 0.23744692641349954\n",
      "min entropy is between 2 and 4, so it's language is english.\n"
     ]
    }
   ],
   "source": [
    "print(\"entropy between 4 and 1 is {}\".format(entropy(valuecommon4,valuecommon1)))\n",
    "print(\"entropy between 4 and 2 is {}\".format(entropy(valuecommon4,valuecommon2)))\n",
    "print(\"entropy between 4 and 3 is {}\".format(entropy(valuecommon4,valuecommon3)))\n",
    "print(\"min entropy is between 2 and 4, so it's language is english.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question #2\n",
    "\n",
    "For this question consider the [Car Evaluation Data Set](https://archive.ics.uci.edu/ml/datasets/Car+Evaluation) from UCI. Here is the [direct link](https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data) to the dataset.\n",
    "\n",
    "Make [contingency tables](https://en.wikipedia.org/wiki/Contingency_table#:~:text=In%20statistics%2C%20a%20contingency%20table,%2C%20engineering%2C%20and%20scientific%20research.) of the columns (using [`crosstab`](https://pandas.pydata.org/docs/reference/api/pandas.crosstab.html) function from [pandas](https://pandas.pydata.org)) and figure out which pairs of columns are dependent and independent. Explain your result using statistical tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power_divergenceResult(statistic=0.0, pvalue=1.0)\n",
      "Power_divergenceResult(statistic=0.0, pvalue=1.0)\n",
      "Power_divergenceResult(statistic=0.0, pvalue=1.0)\n",
      "Power_divergenceResult(statistic=0.0, pvalue=1.0)\n",
      "Power_divergenceResult(statistic=0.0, pvalue=1.0)\n",
      "Power_divergenceResult(statistic=2554.0555555555557, pvalue=0.0)\n",
      "Power_divergenceResult(statistic=2059.4444444444443, pvalue=0.0)\n",
      "Power_divergenceResult(statistic=2515.847222222222, pvalue=0.0)\n",
      "Power_divergenceResult(statistic=2034.0, pvalue=0.0)\n",
      "Power_divergenceResult(statistic=2104.4814814814813, pvalue=0.0)\n",
      "Power_divergenceResult(statistic=2122.0, pvalue=0.0)\n",
      "6th column is dependent with each columns...\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "\n",
    "data=pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data\",header=None)\n",
    "\n",
    "a=pd.crosstab(data[0],data[1])\n",
    "b=pd.crosstab(data[1],data[2])\n",
    "c=pd.crosstab(data[2],data[3])\n",
    "d=pd.crosstab(data[3],data[4])\n",
    "e=pd.crosstab(data[4],data[5])\n",
    "f=pd.crosstab(data[5],data[6])\n",
    "g=pd.crosstab(data[4],data[6])\n",
    "h=pd.crosstab(data[3],data[6])\n",
    "i=pd.crosstab(data[2],data[6])\n",
    "j=pd.crosstab(data[1],data[6])\n",
    "k=pd.crosstab(data[0],data[6])\n",
    "\n",
    "print(chisquare(a,axis=None))\n",
    "print(chisquare(b,axis=None))\n",
    "print(chisquare(c,axis=None))\n",
    "print(chisquare(d,axis=None))\n",
    "print(chisquare(e,axis=None))\n",
    "print(chisquare(f,axis=None))\n",
    "print(chisquare(g,axis=None))\n",
    "print(chisquare(h,axis=None))\n",
    "print(chisquare(i,axis=None))\n",
    "print(chisquare(j,axis=None))\n",
    "print(chisquare(k,axis=None))\n",
    "print(\"6th column is dependent with each columns...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question #3\n",
    "\n",
    "For this question, use [Default of Credit Card Clients Data Set]() from UCI. Here is the [direct link](https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls) to the dataset.\n",
    "\n",
    "Your tasks are\n",
    "\n",
    "* Inspect the dataset.\n",
    "* Would it be appropriate to form a linear regression model to predict the `default payment next month` variable? Explain.\n",
    "* Form a [contingency table](https://en.wikipedia.org/wiki/Contingency_table#:~:text=In%20statistics%2C%20a%20contingency%20table,%2C%20engineering%2C%20and%20scientific%20research.) of the columns `SEX` vs `default payment next month` and `EDUCATION` vs `default payment next month`.\n",
    "* Are there statistically verifiable relationships between credit card defaults, the gender of and the education level the borrower? Which is stronger? Quantify your analysis using [Chi Square Test](https://en.wikipedia.org/wiki/Chi-squared_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The target column consits of binary numbers, so this is not a linear regression problem.  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_excel(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\")\n",
    "print(\" The target column consits of binary numbers, so this is not a linear regression problem.  \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop(0,axis=0)\n",
    "y=data[\"Y\"]\n",
    "\n",
    "X=X.drop(\"Y\",axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.drop(0,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>...</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>X19</th>\n",
       "      <th>X20</th>\n",
       "      <th>X21</th>\n",
       "      <th>X22</th>\n",
       "      <th>X23</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID</td>\n",
       "      <td>LIMIT_BAL</td>\n",
       "      <td>SEX</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>MARRIAGE</td>\n",
       "      <td>AGE</td>\n",
       "      <td>PAY_0</td>\n",
       "      <td>PAY_2</td>\n",
       "      <td>PAY_3</td>\n",
       "      <td>PAY_4</td>\n",
       "      <td>...</td>\n",
       "      <td>BILL_AMT4</td>\n",
       "      <td>BILL_AMT5</td>\n",
       "      <td>BILL_AMT6</td>\n",
       "      <td>PAY_AMT1</td>\n",
       "      <td>PAY_AMT2</td>\n",
       "      <td>PAY_AMT3</td>\n",
       "      <td>PAY_AMT4</td>\n",
       "      <td>PAY_AMT5</td>\n",
       "      <td>PAY_AMT6</td>\n",
       "      <td>default payment next month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>29996</td>\n",
       "      <td>220000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>88004</td>\n",
       "      <td>31237</td>\n",
       "      <td>15980</td>\n",
       "      <td>8500</td>\n",
       "      <td>20000</td>\n",
       "      <td>5003</td>\n",
       "      <td>3047</td>\n",
       "      <td>5000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>29997</td>\n",
       "      <td>150000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>8979</td>\n",
       "      <td>5190</td>\n",
       "      <td>0</td>\n",
       "      <td>1837</td>\n",
       "      <td>3526</td>\n",
       "      <td>8998</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>29998</td>\n",
       "      <td>30000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>20878</td>\n",
       "      <td>20582</td>\n",
       "      <td>19357</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22000</td>\n",
       "      <td>4200</td>\n",
       "      <td>2000</td>\n",
       "      <td>3100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>29999</td>\n",
       "      <td>80000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>52774</td>\n",
       "      <td>11855</td>\n",
       "      <td>48944</td>\n",
       "      <td>85900</td>\n",
       "      <td>3409</td>\n",
       "      <td>1178</td>\n",
       "      <td>1926</td>\n",
       "      <td>52964</td>\n",
       "      <td>1804</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30000</th>\n",
       "      <td>30000</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36535</td>\n",
       "      <td>32428</td>\n",
       "      <td>15313</td>\n",
       "      <td>2078</td>\n",
       "      <td>1800</td>\n",
       "      <td>1430</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30001 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0         X1   X2         X3        X4   X5     X6     X7  \\\n",
       "0             ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2   \n",
       "1              1      20000    2          2         1   24      2      2   \n",
       "2              2     120000    2          2         2   26     -1      2   \n",
       "3              3      90000    2          2         2   34      0      0   \n",
       "4              4      50000    2          2         1   37      0      0   \n",
       "...          ...        ...  ...        ...       ...  ...    ...    ...   \n",
       "29996      29996     220000    1          3         1   39      0      0   \n",
       "29997      29997     150000    1          3         2   43     -1     -1   \n",
       "29998      29998      30000    1          2         2   37      4      3   \n",
       "29999      29999      80000    1          3         1   41      1     -1   \n",
       "30000      30000      50000    1          2         1   46      0      0   \n",
       "\n",
       "          X8     X9  ...        X15        X16        X17       X18       X19  \\\n",
       "0      PAY_3  PAY_4  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2   \n",
       "1         -1     -1  ...          0          0          0         0       689   \n",
       "2          0      0  ...       3272       3455       3261         0      1000   \n",
       "3          0      0  ...      14331      14948      15549      1518      1500   \n",
       "4          0      0  ...      28314      28959      29547      2000      2019   \n",
       "...      ...    ...  ...        ...        ...        ...       ...       ...   \n",
       "29996      0      0  ...      88004      31237      15980      8500     20000   \n",
       "29997     -1     -1  ...       8979       5190          0      1837      3526   \n",
       "29998      2     -1  ...      20878      20582      19357         0         0   \n",
       "29999      0      0  ...      52774      11855      48944     85900      3409   \n",
       "30000      0      0  ...      36535      32428      15313      2078      1800   \n",
       "\n",
       "            X20       X21       X22       X23                           Y  \n",
       "0      PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
       "1             0         0         0         0                           1  \n",
       "2          1000      1000         0      2000                           1  \n",
       "3          1000      1000      1000      5000                           0  \n",
       "4          1200      1100      1069      1000                           0  \n",
       "...         ...       ...       ...       ...                         ...  \n",
       "29996      5003      3047      5000      1000                           0  \n",
       "29997      8998       129         0         0                           0  \n",
       "29998     22000      4200      2000      3100                           1  \n",
       "29999      1178      1926     52964      1804                           1  \n",
       "30000      1430      1000      1000      1000                           1  \n",
       "\n",
       "[30001 rows x 25 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.crosstab(X[\"X2\"],y)\n",
    "b=pd.crosstab(X[\"X3\"],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Y</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9015</td>\n",
       "      <td>2873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14349</td>\n",
       "      <td>3763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Y       0     1\n",
       "X2             \n",
       "1    9015  2873\n",
       "2   14349  3763"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"sex vs payment\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Y</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X3</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8549</td>\n",
       "      <td>2036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10700</td>\n",
       "      <td>3330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3680</td>\n",
       "      <td>1237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>262</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>43</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Y       0     1\n",
       "X3             \n",
       "0      14     0\n",
       "1    8549  2036\n",
       "2   10700  3330\n",
       "3    3680  1237\n",
       "4     116     7\n",
       "5     262    18\n",
       "6      43     8"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"education vs payment\")\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power_divergenceResult(statistic=11277.109866666666, pvalue=0.0)\n",
      "Power_divergenceResult(statistic=71717.81573333332, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "print(chisquare(a,axis=None))\n",
    "print(chisquare(b,axis=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### P values are 0 so these features has a relationship between default payment and the test value of education is higher, so that means education is more related to payment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question #4\n",
    "\n",
    "For this question, use the [Iris Dataset](https://archive.ics.uci.edu/ml/datasets/iris) from UCI.  Here is the [direct link](https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data) to the dataset.\n",
    "\n",
    "Your tasks are\n",
    "\n",
    "* Form a [K-NN](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) model for this dataset.\n",
    "* Test your model on random samples of your data and calculate its accuracy.\n",
    "* Repeat your calculation 100 times and give an interval of accuracy values leaving the best 2.5% and worst 2.5% accuracy values.\n",
    "* Is there a better way of doing this without repeating the calculation 100 times? Explain.\n",
    "* Find the best parameter $k$ for your dataset for the K-NN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "X=data.iloc[:,0:4]\n",
    "y=data[4]\n",
    "scores=[]\n",
    "\n",
    "for i in range(100):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n",
    "\n",
    "    \n",
    "    model2.fit(X_train,y_train)\n",
    "    y_preds=model2.predict(X_test)\n",
    "    sc=accuracy_score(y_test,y_preds)\n",
    "    \n",
    "    scores.append(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation can be used instead of for loop...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.97777778, 0.93333333, 0.97777778, 0.91111111, 0.97777778])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Cross validation can be used instead of for loop...\")\n",
    "\n",
    "model3=KNeighborsClassifier(n_neighbors=3)\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "cross_val_score(model3, X, y, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks=[1,2,3,5,10,25,50,100]\n",
    "scores=[]\n",
    "for k in ks:\n",
    "    model4=KNeighborsClassifier(n_neighbors=k)\n",
    "    cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "    a=cross_val_score(model4, X, y, cv=cv)\n",
    "    meana=a.mean()\n",
    "    scores.append(meana)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9644444444444444,\n",
       " 0.9511111111111111,\n",
       " 0.9555555555555555,\n",
       " 0.96,\n",
       " 0.96,\n",
       " 0.9466666666666667,\n",
       " 0.888888888888889,\n",
       " 0.4666666666666667]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =1 is the best k-nn\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"k ={} is the best k-nn\".format(ks[np.argmax(scores)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question #5\n",
    "\n",
    "For this question, we are going to use [Concrete Slump Test Dataset](https://archive.ics.uci.edu/ml/datasets/Concrete+Slump+Test) from UCI. Here is the [direct link](https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/slump/slump_test.data) to the dataset.\n",
    "\n",
    "Your tasks are\n",
    "\n",
    "* Form three separate linear regression model for the following dependent variables:\n",
    "\n",
    "  - SLUMP (cm)\n",
    "  - FLOW (cm)\n",
    "  - 28-day Compressive Strength (Mpa)\n",
    "  \n",
    "* Compare how well these models fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>Cement</th>\n",
       "      <th>Slag</th>\n",
       "      <th>Fly ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>SP</th>\n",
       "      <th>Coarse Aggr.</th>\n",
       "      <th>Fine Aggr.</th>\n",
       "      <th>SLUMP(cm)</th>\n",
       "      <th>FLOW(cm)</th>\n",
       "      <th>Compressive Strength (28-day)(Mpa)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>904.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>34.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>163.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>843.0</td>\n",
       "      <td>746.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>41.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>162.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>41.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>162.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>838.0</td>\n",
       "      <td>741.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>42.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>154.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>658.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>26.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>248.3</td>\n",
       "      <td>101.0</td>\n",
       "      <td>239.1</td>\n",
       "      <td>168.9</td>\n",
       "      <td>7.7</td>\n",
       "      <td>954.2</td>\n",
       "      <td>640.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>49.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>248.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>239.9</td>\n",
       "      <td>169.1</td>\n",
       "      <td>7.7</td>\n",
       "      <td>949.9</td>\n",
       "      <td>644.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>50.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>101</td>\n",
       "      <td>258.8</td>\n",
       "      <td>88.0</td>\n",
       "      <td>239.6</td>\n",
       "      <td>175.3</td>\n",
       "      <td>7.6</td>\n",
       "      <td>938.9</td>\n",
       "      <td>646.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>50.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>102</td>\n",
       "      <td>297.1</td>\n",
       "      <td>40.9</td>\n",
       "      <td>239.9</td>\n",
       "      <td>194.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>908.9</td>\n",
       "      <td>651.8</td>\n",
       "      <td>27.5</td>\n",
       "      <td>67.0</td>\n",
       "      <td>49.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>103</td>\n",
       "      <td>348.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>223.1</td>\n",
       "      <td>208.5</td>\n",
       "      <td>9.6</td>\n",
       "      <td>786.2</td>\n",
       "      <td>758.1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>48.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      No  Cement   Slag  Fly ash  Water    SP  Coarse Aggr.  Fine Aggr.  \\\n",
       "0      1   273.0   82.0    105.0  210.0   9.0         904.0       680.0   \n",
       "1      2   163.0  149.0    191.0  180.0  12.0         843.0       746.0   \n",
       "2      3   162.0  148.0    191.0  179.0  16.0         840.0       743.0   \n",
       "3      4   162.0  148.0    190.0  179.0  19.0         838.0       741.0   \n",
       "4      5   154.0  112.0    144.0  220.0  10.0         923.0       658.0   \n",
       "..   ...     ...    ...      ...    ...   ...           ...         ...   \n",
       "98    99   248.3  101.0    239.1  168.9   7.7         954.2       640.6   \n",
       "99   100   248.0  101.0    239.9  169.1   7.7         949.9       644.1   \n",
       "100  101   258.8   88.0    239.6  175.3   7.6         938.9       646.0   \n",
       "101  102   297.1   40.9    239.9  194.0   7.5         908.9       651.8   \n",
       "102  103   348.7    0.1    223.1  208.5   9.6         786.2       758.1   \n",
       "\n",
       "     SLUMP(cm)  FLOW(cm)  Compressive Strength (28-day)(Mpa)  \n",
       "0         23.0      62.0                               34.99  \n",
       "1          0.0      20.0                               41.14  \n",
       "2          1.0      20.0                               41.81  \n",
       "3          3.0      21.5                               42.08  \n",
       "4         20.0      64.0                               26.82  \n",
       "..         ...       ...                                 ...  \n",
       "98         0.0      20.0                               49.97  \n",
       "99         2.0      20.0                               50.23  \n",
       "100        0.0      20.0                               50.50  \n",
       "101       27.5      67.0                               49.17  \n",
       "102       29.0      78.0                               48.77  \n",
       "\n",
       "[103 rows x 11 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/slump/slump_test.data\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=LinearRegression()\n",
    "model2=LinearRegression()\n",
    "model3=LinearRegression()\n",
    "data=data.dropna()\n",
    "\n",
    "X0=data.iloc[:,10]\n",
    "X1=data.iloc[:,8]\n",
    "X2=data.iloc[:,9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03001402841743439\n",
      "-0.03842121374001173\n",
      "0.8270377875516006\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model11=LinearRegression()\n",
    "model22=LinearRegression()\n",
    "model33=LinearRegression()\n",
    "data=data.dropna()\n",
    "\n",
    "y=np.array(data.iloc[:,10]).reshape(len(data),1)\n",
    "X1=np.array(data.iloc[:,8]).reshape(len(data),1)\n",
    "X2=np.array(data.iloc[:,9]).reshape(len(data),1)\n",
    "\n",
    "X1_train,X1_test,y1_train,y1_test=train_test_split(X1,y,test_size=0.3)\n",
    "model11.fit(X1_train,y1_train)\n",
    "score11=model11.score(X1_test,y1_test)\n",
    "\n",
    "X2_train,X2_test,y2_train,y2_test=train_test_split(X2,y,test_size=0.3)\n",
    "model22.fit(X2_train,y2_train)\n",
    "score2=model22.score(X2_test,y2_test)\n",
    "\n",
    "X3_train,X3_test,y3_train,y3_test=train_test_split(X1,X2,test_size=0.3)\n",
    "model33.fit(X3_train,y3_train)\n",
    "score3=model33.score(X3_test,y3_test)\n",
    "\n",
    "print(score1)\n",
    "print(score2)\n",
    "print(score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 is better when it is close to 1, so model 3 fits pretty well. (Slump vs Flow) acc is 0.8270377875516006\n"
     ]
    }
   ],
   "source": [
    "print(\"R^2 is better when it is close to 1, so model 3 fits pretty well. (Slump vs Flow) acc is {}\".format(score3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
